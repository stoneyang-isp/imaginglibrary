\documentclass[a4paper]{article}

\usepackage[top=1in,bottom=1.25in,left=1.25in,right=1.25in]{geometry}

\hyphenation{op-tical net-works semi-conduc-tor IEEEtran}

\title{\LARGE \bf
Reference on\\Imaging Science and Engineering
}

\author{Fan Yang}

\begin{document}

\maketitle

\begin{abstract}
Imaging devices lie in the foremost phase in the pipeline of the artificial vision system that mimic human vision system. 
The quality of the acquisition and the in-place processing are at the stake of the computation that take place in the succeeding steps. 
This is a self-assembled reference indexing article in the field of imaging science and engineering, plus to some extent on the relative topics in the field of vision science, optics, psychophysics, and computer science. 
The collected literature are organized into different categories and are updated timely, I'll try my best to gurantee this. 
\end{abstract}

Imaging, especially color imaging, is an important and thriving field with the aim of acquiring high-quality images for both human and machines.

The literature are collected and organized into the following categories:
\begin{enumerate}
\item Scene modeling;
\item Human vision system;
\item Optical imaging;
\item Electronical imaging; and
\item Digital image processing.
\end{enumerate}
Each piece of the literature is listed with a few sentences (at least one) to introduce it. 

\section{Scene modeling}

Imaging devices capture digital/analogue images of the selected part of the natural/synthetic scene. 
The underlying principle is the natural law of reflectance of light. 
Light propagates in media such as air, water, and many other objects that are transparent. 
When travelling in the air, light may encounter different weather condition that caused the illumination complex. 
Also, in different time of a day on this planet, natural illuminant (i.e., sun in the day, and stars at night) fires different light. 

Radiometric, photometric, and colorimetric

Typical illuminants: color temperature,,,

Underwater: 

Bad weather conditions: haze, fog, rain

Misc: sky

\section{Human vision system}

\subsection{Lightness constancy}

Lightness, illumination, and gradients \cite{Todorovic2006}.

Shading and reflectance \cite{Adelson1996}.

A gestalt account of lightness illusions \cite{Gilchrist2014}, Theoretical approaches to lightness and perception \cite{Gilchrist2015}.

Lightness constancy and illumination discounting \cite{Logvinenko2011}. 

\subsection{Color constancy}

\subsection{Shape constancy}

\cite{Pizlo1994}

\section{Optical imaging}

About lenses

\section{Electronical imaging}

\subsection{APS vs. DPS}

\subsection{Noise}

\section{Digital image processing}

HDRI tech report \cite{SMPTE2015}. 

\subsection{Acquisition}

Cameras: Narasimha {\it et al.} \cite{Narasimha2015}. 

\cite{Agrawal2005}. 

\subsection{Color management}

\subsubsection{Tone reproduction}

Li {\it et al.} \cite{Li2005}.

Meylan and S\"{u}sstrunk \cite{Meylan2006,Meylan2007}.

Mantiuk {\it et al.} \cite{Mantiuk2008} with supplementary material \cite{Mantiuk2008supp}. 

Improved bilateral filtering by Chen {\it et al.} \cite{Chen:2007}. 

Real-time noise-aware tone mapping by Eilertsen {\it et al.} \cite{Eilertsen2015}, with supplementary material in \cite{Eilertsen2015supp}.

Ji {\it et al.} on balancing contrast and ringing effect \cite{Ji2014}.

Local adaptation model \cite{Vangorp2015}.

Evaluation of tone reproduction algorithms, 
for images \cite{Ledda2005,Mantiuk2011,Kuhna2011,Narwaria2015,Narwaria2015b}, 
for videos \cite{Eilertsen2013} with a short version \cite{Eilertsen2013short}, 
and for other factors such as screen reflection \cite{Melo2015,Melo2015b}, 
view experience \cite{Nasiopoulos2014}. 

Data set \cite{Froehlich2014}.

\subsubsection{Illumination estimation}

Survey paper written by Foster \cite{Foster2011}, Gijsenij {\it et al.} \cite{Gijsenij2011}, Barnard {\it et al.} \cite{Barnard2002a,Barnard2002b}.
Book chapters such as \cite{Wandell2003,RoyChoudhury2015a,RoyChoudhury2015b,Prayagi2015}.

methods can also categorized by whether they work directly from color values (i.e., color domain) or from values obtained from the image¡¯s spatial information (e.g., image gradients/frequencies) \cite{Cheng2014}.

Quoted from \cite{Cheng2014}: spatial information does not provide any additional information that cannot be obtained directly from the color distribution and that the indirect aim of spatial-domain methods is to obtain large color differences for estimating the illumination direction. 

Quoted from \cite{Granzier2009}: color constancy must be achieved by relying on relationships that are insensitive to the illumination rather than by explicitly judging the color of the illumination. 

Spatial structure related: Mizokami and Yaguci \cite{Mizokami2014}.

Gray world assumption by Buchsbaum \cite{Buchsbaum1980}, and improvement to avoid sensitivity issue \cite{Gershon1987}. 

White patch

Ebner \cite{Ebner2007,Ebner2012}.

Wandell \cite{Maloney1986}.

Mutual reflection \cite{Funt1991}. 

Learning-based \cite{Bianco2012,Bianco2014,Nguyen2014,Robles-Kelly2015}. 

Memory color related: faces \cite{Bianco2012,Bianco2014}, sky \cite{Kawakami2013}. 

In video \cite{Robles-Kelly2015}. 

Color Constancy with Spatio-Spectral Statistics \cite{Chakrabarti2012}.

Modeling Radiometric Uncertainty for Vision with Tone-mapped Color Images \cite{Chakrabarti2014}. 

Color Constancy and Non-Uniform Illumination \cite{Bleier2011}.

\subsubsection{Chromatic adaptation}



\subsubsection{Color appearance models}

iCAM \cite{Fairchild2002}. 

\cite{Calabria2001}. 

\subsubsection{Color appearance vs. Tone reproduction}

\subsection{Restoration \& Enhancement}

\subsubsection{Haze removal}

\subsubsection{Raindrop removal}

\subsubsection{Shadow removal}

\cite{Yuan2015}

\subsubsection{Noise reduction}

Bell {\it et al.} \cite{Bell2008}

in capture \cite{Hasinoff2010}

\subsubsection{Super resolution}

\subsection{Misc.}

Demosaiking \cite{Zhang2007}.

\section{Conclusions}

\bibliographystyle{acm}
\bibliography{imaginglibrary}

\end{document}