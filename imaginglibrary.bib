% This file was created with JabRef 2.10.
% Encoding: GBK


@InBook{Adelson1996,
  Title                    = {Perception as Baysian Inference},
  Author                   = {E.H. Adelson and A.P. Pentland},
  Chapter                  = {11 The perception of shading and reflectance},
  Editor                   = {D. Knill and W. Richards},
  Pages                    = {409-423},
  Publisher                = {Cambridge University Press},
  Year                     = {1996},

  Address                  = {New York},

  File                     = {:Papers\\HDRI\\HVS\\Adelson1996.pdf:PDF},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.22},
  Url                      = {http://persci.mit.edu/pub_pdfs/shading96.pdf}
}

@Article{Agrawal2005,
  Title                    = {Removing Photography Artifacts Using Gradient Projection and Flash-exposure Sampling},
  Author                   = {Agrawal, Amit and Raskar, Ramesh and Nayar, Shree K. and Li, Yuanzhen},
  Journal                  = {ACM Trans. Graph.},
  Year                     = {2005},

  Month                    = {July},
  Number                   = {3},
  Pages                    = {828--835},
  Volume                   = {24},

  Acmid                    = {1073269},
  Address                  = {New York, NY, USA},
  Doi                      = {10.1145/1073204.1073269},
  File                     = {:Papers\\HDRI\\Recovery\\agrawal2005.pdf:PDF},
  ISSN                     = {0730-0301},
  Issue_date               = {July 2005},
  Keywords                 = {flash, flash-exposure sampling, gradient projection, high dynamic range (HDR) imaging, reflection removal},
  Numpages                 = {8},
  Publisher                = {ACM},
  Url                      = {http://doi.acm.org/10.1145/1073204.1073269}
}

@Article{Barnard2002a,
  Title                    = {A comparison of computational color constancy algorithms. {I}: Methodology and experiments with synthesized data},
  Author                   = {K. Barnard and V. Cardei and B. Funt},
  Journal                  = {IEEE Transactions on Image Processing},
  Year                     = {2002},

  Month                    = {Sep},
  Number                   = {9},
  Pages                    = {972-984},
  Volume                   = {11},

  Doi                      = {10.1109/TIP.2002.802531},
  File                     = {:Papers\\HDRI\\ColorAppearance\\barnard2002a.pdf:PDF},
  ISSN                     = {1057-7149},
  Keywords                 = {correlation methods;image colour analysis;neural nets;Retinex method;algorithm performance;chromaticity;clipping;color by correlation method;computational color constancy algorithms;gamut-mapping method;gray world methods;illumination invariant image;neural net method;reflectance spectra;scene illuminant;specularities;synthesized data;Cameras;Color;Computer networks;Correlation;Helium;Layout;Lighting;Neural networks;Reflectivity;Testing}
}

@Article{Barnard2002b,
  Title                    = {A comparison of computational color constancy Algorithms. {II}. Experiments with image data},
  Author                   = {K. Barnard and L. Martin and A. Coath and B. Funt},
  Journal                  = {IEEE Transactions on Image Processing},
  Year                     = {2002},

  Month                    = {Sep},
  Number                   = {9},
  Pages                    = {985-996},
  Volume                   = {11},

  Doi                      = {10.1109/TIP.2002.802529},
  File                     = {:Papers\\HDRI\\ColorAppearance\\barnard2002b.pdf:PDF},
  ISSN                     = {1057-7149},
  Keywords                 = {correlation methods;image colour analysis;neural nets;Retinex method;chromaticity;color by correlation method;computational color constancy algorithms;gamut-mapping method;gray world methods;illumination conditions;image data;images;input data statistics;neural net method;pixel intensity;preprocessing strategies;scene illuminant;synthesized data;Application software;Calibration;Cameras;Correlation;Layout;Lighting;Neural networks;Object recognition;Statistics;Testing}
}

@InProceedings{Bell2008,
  Title                    = {Noise in high dynamic range imaging},
  Author                   = {A. A. Bell and C. Seiler and J. N. Kaftan and T. Aach},
  Booktitle                = {2008 15th IEEE International Conference on Image Processing},
  Year                     = {2008},
  Month                    = {Oct},
  Pages                    = {561-564},

  Doi                      = {10.1109/ICIP.2008.4711816},
  File                     = {:Papers\\HDRI\\NoiseReduction\\bell2008.pdf:PDF},
  ISSN                     = {1522-4880},
  Keywords                 = {cameras;image denoising;linearisation techniques;transfer functions;SNR;digital cameras;high dynamic range imaging;image acquisition process;noise reduction;nonlinear camera transfer function;Computer vision;Digital cameras;Dynamic range;Layout;Lighting;Noise reduction;Optical filters;Optical imaging;Optical sensors;Transfer functions;high dynamic range imaging;noise;noise reduction}
}

@Article{Bianco2014,
  Title                    = {Adaptive Color Constancy Using Faces},
  Author                   = {S. Bianco and R. Schettini},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2014},

  Month                    = {Aug},
  Number                   = {8},
  Pages                    = {1505-1518},
  Volume                   = {36},

  Doi                      = {10.1109/TPAMI.2013.2297710},
  File                     = {:Papers\\HDRI\\ColorAppearance\\bianco2014.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {estimation theory;face recognition;image colour analysis;lighting;object detection;RAW images;adaptive color constancy algorithm;global varying color correction;heterogeneous data set;perceptual significance;scene illumination correction;scene illumination estimation;skin regions;spatial varying color correction;statistical significance;Algorithm design and analysis;Cameras;Estimation;Histograms;Image color analysis;Lighting;Skin;Color constancy;face detection;global illuminant estimation;local illuminant estimation}
}

@InProceedings{Bianco2012,
  Title                    = {Color constancy using faces},
  Author                   = {S. Bianco and R. Schettini},
  Booktitle                = {Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on},
  Year                     = {2012},
  Month                    = {June},
  Pages                    = {65-72},

  Doi                      = {10.1109/CVPR.2012.6247659},
  File                     = {:Papers\\HDRI\\ColorAppearance\\bianco2012.pdf:PDF},
  ISSN                     = {1063-6919},
  Keywords                 = {cameras;face recognition;image colour analysis;RAW format;color constancy;color space;color statistics;digital still camera processing pipelines;embedded face detector;gray level images;illuminant estimation;photographic images;portraits;public image dataset;real face detector;skin colors;Cameras;Detectors;Estimation;Histograms;Image color analysis;Skin;Standards}
}

@InProceedings{Bleier2011,
  Title                    = {Color constancy and non-uniform illumination: Can existing algorithms work?},
  Author                   = {M. Bleier and C. Riess and S. Beigpour and E. Eibenberger and E. Angelopoulou and T. Tr\"{o}ger and A. Kaup},
  Booktitle                = {Computer Vision Workshops (ICCV Workshops), 2011 IEEE International Conference on},
  Year                     = {2011},
  Month                    = {Nov},
  Pages                    = {774-781},

  Doi                      = {10.1109/ICCVW.2011.6130331},
  File                     = {:Papers\\HDRI\\ColorAppearance\\bleier2011.pdf:PDF},
  Keywords                 = {image colour analysis;image fusion;image resolution;image segmentation;lighting;regression analysis;color bias removal;color constancy methods;fusion methodologies;local illuminant estimation;nonuniform illumination;regression;superpixel segmentation;Bayesian methods;Databases;Estimation;Image color analysis;Image segmentation;Light sources;Lighting}
}

@Article{Buchsbaum1980,
  Title                    = {A spatial processor model for object colour perception},
  Author                   = {G. Buchsbaum},
  Journal                  = {Journal of the Franklin Institute},
  Year                     = {1980},
  Number                   = {1},
  Pages                    = {1-26},
  Volume                   = {310},

  Abstract                 = {A comprehensive mathematical model to account for colour constancy is formulated. Since the visual system is able to measure true object colour in complex scenes under a broad range of spectral compositions, for the illumination; it is assumed that the visual system must implicitly estimate and illuminant. The basic hypothesis is that the estimate of the illuminant is made on the basis of spatial information from the entire visual field. This estimate is then used by the visual system to arrive at an estimate of the (object) reflectance of the various subfields in the complex visual scene. The estimates are made by matching the inputs to the system to linear combinations of fixed bases and standards in the colour space. The model provides a general unified mathematical framework for related psychophysical phenomenology.},
  Doi                      = {http://dx.doi.org/10.1016/0016-0032(80)90058-7},
  File                     = {:Papers\\HDRI\\ColorAppearance\\buchsbaum1980.pdf:PDF},
  ISSN                     = {0016-0032},
  Url                      = {http://www.sciencedirect.com/science/article/pii/0016003280900587}
}

@Article{Calabria2001,
  Title                    = {Herding {CATs}: A Comparison of Linear Chromatic-Adaptation Transforms for {CIECAM97}s},
  Author                   = {Calabria, Anthony J. and Fairchild, Mark D.},
  Journal                  = {Color and Imaging Conference},
  Year                     = {2001},

  Month                    = {January},
  Number                   = {1},
  Pages                    = {174-178},
  Volume                   = {2001},

  Abstract                 = {There are currently five transformation matrices being considered for use in the linear chromatic-adaptation transform in a revision of the CIECAM97s color appearance model. Four of the matrices were developed independently for the purpose of transforming tristimulus values to spectrally
sharpened RGB responses. The fifth is the Hunt-Pointer-Estevez transform of CIE tristimulus values to normalized cone responsivities. RGB images were transformed between CIE illuminant D65 and CIE illuminant A white point using each of the matrices and results were examined visually. In addition,
pixel-wise &#916;<i>E</i>
<sub>94</sub>
<sup>*</sup> and &#916;<i>E</i>
<sub>ab</sub>
<sup>*</sup> calculations between corresponding color images showed the performance of the four XYZ-to-RGB transformation matrices was essentially equal. In a complex image, these slight differences would
most likely go undetected.},
  File                     = {Calabria2001.pdf:Papers\\HDRI\\ColorAppearance\\Fairchild\\Calabria2001.pdf:PDF},
  Url                      = {http://www.ingentaconnect.com/content/ist/cic/2001/00002001/00000001/art00032}
}

@Article{Chakrabarti2012,
  Title                    = {Color Constancy with Spatio-Spectral Statistics},
  Author                   = {A. Chakrabarti and K. Hirakawa and T. Zickler},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2012},

  Month                    = {Aug},
  Number                   = {8},
  Pages                    = {1509-1519},
  Volume                   = {34},

  Doi                      = {10.1109/TPAMI.2011.252},
  File                     = {:Papers\\HDRI\\ColorAppearance\\chakrabarti2012.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {band-pass filters;image colour analysis;maximum likelihood estimation;color constancy problem;color images;dominating scene illuminant;maximum likelihood approach;maximum likelihood estimation;spatial band-pass filters;spatio-spectral statistics;spectral distribution;statistical prior information;white balanced images;Color;Covariance matrix;Image color analysis;Lighting;Maximum likelihood estimation;Training;Color constancy;illumination statistics.;maximum likelihood;spatial correlations;statistical modeling}
}

@Article{Chakrabarti2014,
  Title                    = {Modeling Radiometric Uncertainty for Vision with Tone-Mapped Color Images},
  Author                   = {A. Chakrabarti and Y. Xiong and B. Sun and T. Darrell and D. Scharstein and T. Zickler and K. Saenko},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {2014},

  Month                    = {Nov},
  Number                   = {11},
  Pages                    = {2185-2198},
  Volume                   = {36},

  Doi                      = {10.1109/TPAMI.2014.2318713},
  File                     = {:Papers\\HDRI\\ColorAppearance\\chakrabarti2014.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {computer vision;image colour analysis;statistical distributions;computer vision systems;digital cameras;linear color measurements;linear scene colors;probability distribution;radiometric uncertainty;tone-mapped color images;visual inference;Calibration;Cameras;Image color analysis;Polynomials;Radiometry;Transform coding;Uncertainty;HDR imaging;Radiometric calibration;camera response functions;deblurring;depth estimation;image fusion;image restoration;photometric stereo;signal-dependent noise;statistical models;tone-mapping}
}

@Article{Chen:2007,
  Title                    = {Real-time Edge-aware Image Processing with the Bilateral Grid},
  Author                   = {Chen, Jiawen and Paris, Sylvain and Durand, Fr{\'e}do},
  Journal                  = {ACM Trans. Graph.},
  Year                     = {2007},

  Month                    = jul,
  Number                   = {3},
  Volume                   = {26},

  Acmid                    = {1276506},
  Address                  = {New York, NY, USA},
  Articleno                = {103},
  Doi                      = {10.1145/1276377.1276506},
  File                     = {:Papers\\HDRI\\ToneMapping\\Local\\Durand\\chen2007.pdf:PDF},
  ISSN                     = {0730-0301},
  Issue_date               = {July 2007},
  Keywords                 = {bilateral filter, computational photography, edge-aware image processing, real-time video processing},
  Publisher                = {ACM},
  Review                   = {http://groups.csail.mit.edu/graphics/bilagrid/},
  Url                      = {http://doi.acm.org/10.1145/1276377.1276506}
}

@Article{Cheng2014,
  Title                    = {Illuminant estimation for color constancy: why spatial-domain methods work and the role of the color distribution},
  Author                   = {Dongliang Cheng and Dilip K. Prasad and Michael S. Brown},
  Journal                  = {J. Opt. Soc. Am. A},
  Year                     = {2014},

  Month                    = {May},
  Number                   = {5},
  Pages                    = {1049--1058},
  Volume                   = {31},

  Abstract                 = {Color constancy is a well-studied topic in color vision. Methods are generally categorized as (1)\&\#xA0;low-level statistical methods, (2)\&\#xA0;gamut-based methods, and (3)\&\#xA0;learning-based methods. In this work, we distinguish methods depending on whether they work directly from color values (i.e., color domain) or from values obtained from the image\&\#x2019;s spatial information (e.g., image gradients/frequencies). We show that spatial information does not provide any additional information that cannot be obtained directly from the color distribution and that the indirect aim of spatial-domain methods is to obtain large color differences for estimating the illumination direction. This finding allows us to develop a simple and efficient illumination estimation method that chooses bright and dark pixels using a projection distance in the color distribution and then applies principal component analysis to estimate the illumination direction. Our method gives state-of-the-art results on existing public color constancy datasets as well as on our newly collected dataset (NUS dataset) containing 1736 images from eight different high-end consumer cameras.},
  Doi                      = {10.1364/JOSAA.31.001049},
  File                     = {:Papers\\HDRI\\ColorAppearance\\cheng2014.pdf:PDF},
  Keywords                 = {Cameras; Illumination; Color vision; Color, rendering and metamerism},
  Publisher                = {OSA},
  Url                      = {http://josaa.osa.org/abstract.cfm?URI=josaa-31-5-1049}
}

@InCollection{RoyChoudhury2015,
  Title                    = {6 - Chromatic adaptation and colour constancy },
  Author                   = {A.K. Roy Choudhury},
  Booktitle                = {Principles of Colour and Appearance Measurement },
  Publisher                = {Woodhead Publishing},
  Year                     = {2015},

  Address                  = {Oxford},
  Editor                   = {Choudhury, Asim Kumar Roy},
  Pages                    = {214-264},

  Abstract                 = {Abstract With change of illumination the sensitivity of our eyes also changes due to chromatic adaptation, in a way such that the colour of the object remains approximately constant. Various chromatic adaptation models formulated by Hunt, Nayatani and \{CIE\} (CIECAM97s and CIECAM02) are discussed in detail. Different light sources can result in different colours of the same object surface. Fortunately, human beings have colour constancy: they perceive the same object colour despite large changes in illumination. A number of colour constancy indices, dependent and independent of chromatic adaptation, are discussed. },
  Doi                      = {http://dx.doi.org/10.1533/9781782423881.214},
  File                     = {:Papers\\HDRI\\ColorAppearance\\choudhury2015.pdf:PDF},
  ISBN                     = {978-1-78242-367-6},
  Keywords                 = {colour appearance},
  Url                      = {http://www.sciencedirect.com/science/article/pii/B978178242367650006X}
}

@Article{Ebner2012,
  Title                    = {A Computational Model for Color Perception},
  Author                   = {Marc Ebner},
  Journal                  = {Bio-Algorithms and Med-Systems},
  Year                     = {2012},
  Number                   = {4},
  Pages                    = {387-415},
  Volume                   = {8},

  File                     = {:Papers\\HDRI\\ColorAppearance\\ebner2012.pdf:PDF;:Papers\\HDRI\\ColorAppearance\\ebner2012_compact.pdf:PDF},
  Owner                    = {yangfan},
  Review                   = {http://stubber.math-inf.uni-greifswald.de/~ebner/resources/uniG/colorPerception.pdf},
  Timestamp                = {2016.04.21},
  Url                      = {http://www.degruyter.com/view/j/bams.2012.8.issue-4/bams-2012-0028/bams-2012-0028.xml?format=INT}
}

@Article{Eilertsen2015,
  Title                    = {Real-time Noise-aware Tone Mapping},
  Author                   = {Eilertsen, Gabriel and Mantiuk, Rafa\l K. and Unger, Jonas},
  Journal                  = {ACM Trans. Graph.},
  Year                     = {2015},

  Month                    = oct,
  Number                   = {6},
  Pages                    = {198:1--198:15},
  Volume                   = {34},

  Acmid                    = {2818092},
  Address                  = {New York, NY, USA},
  Articleno                = {198},
  Doi                      = {10.1145/2816795.2818092},
  File                     = {:Papers\\HDRI\\ToneMapping\\Video\\eilertsen2015.pdf:PDF},
  ISSN                     = {0730-0301},
  Issue_date               = {November 2015},
  Keywords                 = {high dynamic range imaging, tone mapping, video tone mapping},
  Numpages                 = {15},
  Publisher                = {ACM},
  Review                   = {http://www.itn.liu.se/mit/research/computer-graphics-image-processing/real-time-noise-aware-tone-mapping?l=en
http://vcl.itn.liu.se/publications/2015/EMU15/},
  Url                      = {http://doi.acm.org/10.1145/2816795.2818092}
}

@Unpublished{Eilertsen2015supp,
  Title                    = {Real-time noise aware tone mapping---Supplementary material},
  Author                   = {Eilertsen, Gabriel and Mantiuk, Rafa\l K. and Unger, Jonas},
  Year                     = {2015},

  File                     = {:Papers\\HDRI\\ToneMapping\\Video\\eilertsen2015_supplementary.pdf:PDF},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.20},
  Url                      = {http://vcl.itn.liu.se/publications/2015/EMU15/suppmat/SGA15_supplementary.pdf}
}

@InProceedings{Eilertsen2013short,
  Title                    = {Survey and Evaluation of Tone Mapping Operators for HDR Video},
  Author                   = {Eilertsen, Gabriel and Unger, Jonas and Wanat, Robert and Mantiuk, Rafa\l},
  Booktitle                = {ACM SIGGRAPH 2013 Talks},
  Year                     = {2013},

  Address                  = {New York, NY, USA},
  Pages                    = {11:1--11:1},
  Publisher                = {ACM},
  Series                   = {SIGGRAPH '13},

  Acmid                    = {2504473},
  Articleno                = {11},
  Doi                      = {10.1145/2504459.2504473},
  File                     = {Eilertsen2013short.pdf:Papers\\HDRI\\ToneMapping\\Evaluation\\Eilertsen2013short.pdf:PDF},
  ISBN                     = {978-1-4503-2344-4},
  Location                 = {Anaheim, California},
  Numpages                 = {1},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.19},
  Url                      = {http://doi.acm.org/10.1145/2504459.2504473}
}

@InProceedings{Eilertsen2013,
  Title                    = {Evaluation of tone mapping operators for {HDR}-video},
  Author                   = {Gabriel Eilertsen and Robert Wanat and Rafal Mantiuk and Jonas Unger},
  Booktitle                = {Computer Grahpics Forum Special Issue Proceedings of Pacific Graphics},
  Year                     = {2013},
  Editor                   = {B. Levy and X. Tong and K. Yin},
  Month                    = {October},
  Number                   = {7},
  Volume                   = {32},

  File                     = {Eilertsen2013.pdf:Papers\\HDRI\\ToneMapping\\Evaluation\\Eilertsen2013.pdf:PDF},
  Owner                    = {FanYang},
  Timestamp                = {2016.01.19},
  Url                      = {http://liu.diva-portal.org/smash/get/diva2:694640/FULLTEXT01.pdf}
}

@Article{Fairchild2002,
  Title                    = {Meet i{CAM}: A Next-Generation Color Appearance Model},
  Author                   = {Fairchild, Mark D. and Johnson, Garrett M.},
  Journal                  = {Color and Imaging Conference},
  Year                     = {2002},

  Month                    = {January},
  Number                   = {1},
  Pages                    = {33-38},
  Volume                   = {2002},

  Abstract                 = {For over 20 years, color appearance models have evolved to the point of international standardization. These models are capable of predicting the appearance of spatially-simple color stimuli under a wide variety viewing conditions and have been applied to images by treating each pixel
as an independent stimulus. It has been more recently recognized that revolutionary advances in color appearance modeling would require more rigorous treatment of spatial (and perhaps temporal) appearance phenomena. In addition, color appearance models are often more complex than warranted
by the available visual data and limitations in the accuracy and precision of practical viewing conditions. Lastly, issues of color difference measurement are typically treated separate from color appearance. Thus, the stage has been set for a new generation of color appearance models. This
paper presents one such model called iCAM, for image color appearance model. The objectives in formulating iCAM were to simultaneously provide traditional color appearance capabilities, spatial vision attributes, and color difference metrics, in a model simple enough for practical applications.
The framework and initial implementation of the model are presented along with examples that illustrate its performance for chromatic adaptation, appearance scales, color difference, crispening, spreading, high-dynamic-range tone mapping, and image quality measurement. It is expected that
the implementation of this model framework will be refined in the coming years as new data become available.},
  File                     = {Fairchild2002.pdf:Papers\\HDRI\\ColorAppearance\\Fairchild\\Fairchild2002.pdf:PDF},
  Url                      = {http://www.ingentaconnect.com/content/ist/cic/2002/00002002/00000001/art00008}
}

@Article{Foster2011,
  Title                    = {Color constancy },
  Author                   = {David H. Foster},
  Journal                  = {Vision Research },
  Year                     = {2011},
  Note                     = {Vision Research 50th Anniversary Issue: Part 1 },
  Number                   = {7},
  Pages                    = {674 - 700},
  Volume                   = {51},

  Abstract                 = {A quarter of a century ago, the first systematic behavioral experiments were performed to clarify the nature of color constancy¡ªthe effect whereby the perceived color of a surface remains constant despite changes in the spectrum of the illumination. At about the same time, new models of color constancy appeared, along with physiological data on cortical mechanisms and photographic colorimetric measurements of natural scenes. Since then, as this review shows, there have been many advances. The theoretical requirements for constancy have been better delineated and the range of experimental techniques has been greatly expanded; novel invariant properties of images and a variety of neural mechanisms have been identified; and increasing recognition has been given to the relevance of natural surfaces and scenes as laboratory stimuli. Even so, there remain many theoretical and experimental challenges, not least to develop an account of color constancy that goes beyond deterministic and relatively simple laboratory stimuli and instead deals with the intrinsically variable nature of surfaces and illuminations present in the natural world. },
  Doi                      = {http://dx.doi.org/10.1016/j.visres.2010.09.006},
  File                     = {:Papers\\HDRI\\ColorAppearance\\foster2011.pdf:PDF},
  ISSN                     = {0042-6989},
  Keywords                 = {Color constancy},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0042698910004402}
}

@InProceedings{Froehlich2014,
  Title                    = {Creating cinematic wide gamut HDR-video for the evaluation of tone mapping operators and HDR-displays
},
  Author                   = {Froehlich, Jan and Grandinetti, Stefan and Eberhardt, Bernd and Walter, Simon and Schilling, Andreas and Brendel, Harald},
  Booktitle                = {Proc. SPIE 9023, Digital Photography X},
  Year                     = {2014},
  Editor                   = {Nitin Sampat and Radka Tezaur and Sebastiano Battiato and Boyd A. Fowler},
  Month                    = {February},
  Organization             = {SPIE},
  Pages                    = {90230X-90230X-10},
  Volume                   = {9023},

  Abstract                 = {High quality video sequences are required for the evaluation of tone mapping operators and high dynamic range (HDR) displays. We provide scenic and documentary scenes with a dynamic range of up to 18 stops. The scenes are staged using professional film lighting, make-up and set design to enable the evaluation of image and material appearance. To address challenges for HDR-displays and temporal tone mapping operators, the sequences include highlights entering and leaving the image, brightness changing over time, high contrast skin tones, specular highlights and bright, saturated colors. HDR-capture is carried out using two cameras mounted on a mirror-rig. To achieve a cinematic depth of field, digital motion picture cameras with Super-35mm size sensors are used. We provide HDR-video sequences to serve as a common ground for the evaluation of temporal tone mapping operators and HDR-displays. They are available to the scientific community for further research.},
  Doi                      = {10.1117/12.2040003},
  File                     = {Froehlich2014.pdf:Papers\\HDRI\\ToneMapping\\Evaluation\\Froehlich2014.pdf:PDF},
  Journal                  = {Proc. SPIE},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.19},
  Url                      = {http://dx.doi.org/10.1117/12.2040003}
}

@Article{Funt1991,
  Title                    = {Color constancy from mutual reflection},
  Author                   = {Funt, Brian V. and Drew, Mark S. and Ho, Jian},
  Journal                  = {International Journal of Computer Vision},
  Year                     = {1991},
  Number                   = {1},
  Pages                    = {5-24},
  Volume                   = {6},

  Abstract                 = {Mutual reflection occurs when light reflected from one surface illuminates a second surface. In this situation, the color of one or both surfaces can be modified by a color-bleeding effect. In this article we examine how sensor values (e.g., RGB values) are modified in the mutual reflection region and show that a good approximation of the surface spectral reflectance function for each surface can be recovered by using the extra information from mutual reflection. Thus color constancy results from an examination of mutual reflection. Use is made of finite dimensional linear models for ambient illumination and for surface spectral reflectance. If m and n are the number of basis functions required to model illumination and surface spectral reflectance respectively, then we find that the number of different sensor classes p must satisfy the condition p¡Ý(2 n+m)/3. If we use three basis functions to model illumination and three basis functions to model surface spectral reflectance, then only three classes of sensors are required to carry out the algorithm. Results are presented showing a small increase in error over the error inherent in the underlying finite dimension models.},
  Doi                      = {10.1007/BF00127123},
  File                     = {:Papers\\HDRI\\ColorAppearance\\funt1991.pdf:PDF},
  ISSN                     = {1573-1405},
  Url                      = {http://dx.doi.org/10.1007/BF00127123}
}

@InProceedings{Gershon1987,
  Title                    = {From {[R,G,B]} to Surface Reflectance: Computing Color Constant Descriptors in Images},
  Author                   = {Gershon, Ron and Jepson, Allan D. and Tsotsos, John K.},
  Booktitle                = {Proceedings of the 10th International Joint Conference on Artificial Intelligence - Volume 2},
  Year                     = {1987},

  Address                  = {San Francisco, CA, USA},
  Pages                    = {755-758},
  Publisher                = {Morgan Kaufmann Publishers Inc.},
  Series                   = {IJCAI'87},

  Acmid                    = {1626030},
  File                     = {:Papers\\HDRI\\ColorAppearance\\Gershon1987.pdf:PDF},
  Location                 = {Milan, Italy},
  Numpages                 = {4},
  Url                      = {http://dl.acm.org/citation.cfm?id=1625995.1626030}
}

@Article{Gijsenij2011,
  Title                    = {Computational Color Constancy: Survey and Experiments},
  Author                   = {A. Gijsenij and T. Gevers and J. van de Weijer},
  Journal                  = {IEEE Transactions on Image Processing},
  Year                     = {2011},

  Month                    = {Sept},
  Number                   = {9},
  Pages                    = {2475-2489},
  Volume                   = {20},

  Doi                      = {10.1109/TIP.2011.2118224},
  File                     = {:Papers\\HDRI\\ColorAppearance\\Gijsenij2011.pdf:PDF},
  ISSN                     = {1057-7149},
  Keywords                 = {colour vision;computer vision;image colour analysis;learning (artificial intelligence);lighting;computational color constancy;computer vision application;gamut-based method;learning-based method;static method;Adaptation model;Computational modeling;Estimation;Humans;Image color analysis;Light sources;Pixel;Color constancy;illuminant estimation;performance evaluation;survey}
}

@Article{Gilchrist2014,
  Title                    = {A gestalt account of lightness illusions},
  Author                   = {Alan Gilchrist},
  Journal                  = {Perception},
  Year                     = {2014},
  Pages                    = {881-895},
  Volume                   = {43},

  Doi                      = {10.1068/p7751},
  File                     = {:Papers\\HDRI\\HVS\\Gilchrist2014.pdf:PDF},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.22}
}

@Article{Granzier2009,
  Title                    = {Can illumination estimates provide the basis for color constancy?},
  Author                   = {Granzier, Jeroen J. M. and Brenner, Eli and Smeets, Jeroen B. J.},
  Journal                  = {Journal of Vision},
  Year                     = {2009},
  Number                   = {3},
  Pages                    = {18},
  Volume                   = {9},

  Doi                      = {10.1167/9.3.18},
  Eprint                   = {/data/Journals/JOV/933533/jov-9-3-18.pdf},
  File                     = {:Papers\\HDRI\\ColorAppearance\\Granzier2009.pdf:PDF},
  Url                      = {http://dx.doi.org/10.1167/9.3.18}
}

@InProceedings{Hasinoff2010,
  Title                    = {Noise-optimal capture for high dynamic range photography},
  Author                   = {S. W. Hasinoff and F. Durand and W. T. Freeman},
  Booktitle                = {Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on},
  Year                     = {2010},
  Month                    = {June},
  Pages                    = {553-560},

  Doi                      = {10.1109/CVPR.2010.5540167},
  File                     = {:Papers\\HDRI\\NoiseReduction\\hasinoff2010.pdf:PDF},
  ISSN                     = {1063-6919},
  Keywords                 = {image denoising;image sequences;integer programming;photography;HDR;SNR;high dynamic range photography;mixed integer programming problem;noise optimal capture;noise reduction;Additive noise;Cameras;Computer science;Dynamic range;ISO standards;Layout;Linear programming;Noise reduction;Photography;Signal to noise ratio},
  Review                   = {http://people.csail.mit.edu/hasinoff/hdrnoise/},
  Url                      = {http://people.csail.mit.edu/hasinoff/hdrnoise/}
}

@InProceedings{Ji2014,
  Title                    = {Image Pre-compensation: Balancing Contrast and Ringing},
  Author                   = {Yu Ji and Jinwei Ye and Sing Bing Kang and Jingyi Yu},
  Booktitle                = {Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},
  Year                     = {2014},
  Month                    = {June},
  Pages                    = {3350-3357},

  Doi                      = {10.1109/CVPR.2014.428},
  File                     = {Ji2014.pdf:Papers\\HDRI\\ToneMapping\\Global\\Ji2014.pdf:PDF},
  Keywords                 = {image enhancement;balancing contrast;global tone mapping functions;image precompensation;intensity histogram;latent image;sharp reference image;visual acuity enhancement;Convolution;Deconvolution;Dynamic range;Histograms;Image edge detection;Kernel;Visualization;contrast enhancement;defocus compensation;global tone mapping;image deconvolution;image pre-compensation},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.19}
}

@Article{Kawakami2013,
  Title                    = {Camera Spectral Sensitivity and White Balance Estimation from Sky Images},
  Author                   = {Kawakami, Rei and Zhao, Hongxun and Tan, Robby T. and Ikeuchi, Katsushi},
  Journal                  = {International Journal of Computer Vision},
  Year                     = {2013},
  Number                   = {3},
  Pages                    = {187-204},
  Volume                   = {105},

  Abstract                 = {Photometric camera calibration is often required in physics-based computer vision. There have been a number of studies to estimate camera response functions (gamma function), and vignetting effect from images. However less attention has been paid to camera spectral sensitivities and white balance settings. This is unfortunate, since those two properties significantly affect image colors. Motivated by this, a method to estimate camera spectral sensitivities and white balance setting jointly from images with sky regions is introduced. The basic idea is to use the sky regions to infer the sky spectra. Given sky images as the input and assuming the sun direction with respect to the camera viewing direction can be extracted, the proposed method estimates the turbidity of the sky by fitting the image intensities to a sky model. Subsequently, it calculates the sky spectra from the estimated turbidity. Having the sky \$\$RGB\$\$ RGB values and their corresponding spectra, the method estimates the camera spectral sensitivities together with the white balance setting. Precomputed basis functions of camera spectral sensitivities are used in the method for robust estimation. The whole method is novel and practical since, unlike existing methods, it uses sky images without additional hardware, assuming the geolocation of the captured sky is known. Experimental results using various real images show the effectiveness of the method.},
  Doi                      = {10.1007/s11263-013-0632-1},
  File                     = {:Papers\\HDRI\\ColorAppearance\\kawakami2013.pdf:PDF},
  ISSN                     = {1573-1405},
  Url                      = {http://dx.doi.org/10.1007/s11263-013-0632-1}
}

@InProceedings{Kuhna2011,
  Title                    = {Method for evaluating tone mapping operators for natural high dynamic range images},
  Author                   = {Mikko Kuhna and Mikko Nuutinen and Pirkko Oittinen},
  Booktitle                = {Proc. SPIE 7876, Digital Photography VII},
  Year                     = {2011},
  Editor                   = {Francisco H. Imai and Feng Xiao},
  Month                    = {January},
  Organization             = {SPIE},
  Volume                   = {7876},

  Doi                      = {http://dx.doi.org/10.1117/12.872006},
  File                     = {Kuhna2011.pdf:Papers\\HDRI\\ToneMapping\\Evaluation\\Kuhna2011.pdf:PDF},
  Owner                    = {FanYang},
  Timestamp                = {2016.01.19}
}

@Article{Ledda2005,
  Title                    = {Evaluation of Tone Mapping Operators Using a High Dynamic Range Display},
  Author                   = {Ledda, Patrick and Chalmers, Alan and Troscianko, Tom and Seetzen, Helge},
  Journal                  = {ACM Trans. Graph.},
  Year                     = {2005},

  Month                    = jul,
  Number                   = {3},
  Pages                    = {640--648},
  Volume                   = {24},

  Acmid                    = {1073242},
  Address                  = {New York, NY, USA},
  Doi                      = {10.1145/1073204.1073242},
  File                     = {Ledda2005.pdf:Papers\\HDRI\\ToneMapping\\Evaluation\\Ledda2005.pdf:PDF},
  ISSN                     = {0730-0301},
  Issue_date               = {July 2005},
  Keywords                 = {high dynamic range, psychophysics, tone mapping},
  Numpages                 = {9},
  Owner                    = {yangfan},
  Publisher                = {ACM},
  Timestamp                = {2016.04.19},
  Url                      = {http://doi.acm.org/10.1145/1073204.1073242}
}

@Article{Li2005,
  Title                    = {Compressing and Companding High Dynamic Range Images with Subband Architectures},
  Author                   = {Li, Yuanzhen and Sharan, Lavanya and Adelson, Edward H.},
  Journal                  = {ACM Trans. Graph.},
  Year                     = {2005},

  Month                    = jul,
  Number                   = {3},
  Pages                    = {836--844},
  Volume                   = {24},

  Acmid                    = {1073271},
  Address                  = {New York, NY, USA},
  Doi                      = {10.1145/1073204.1073271},
  File                     = {:Papers\\HDRI\\ToneMapping\\Local\\Li\\li2005.pdf:PDF},
  ISSN                     = {0730-0301},
  Issue_date               = {July 2005},
  Keywords                 = {companding, high dynamic range, multiresolution, multiscale, range compression, subbands, tone mapping, wavelets},
  Numpages                 = {9},
  Publisher                = {ACM},
  Review                   = {http://www.mit.edu/~yzli/hdr_companding.htm},
  Url                      = {http://doi.acm.org/10.1145/1073204.1073271}
}

@Article{Logvinenko2011,
  Title                    = {Lightness constancy and illumination discounting},
  Author                   = {Logvinenko, Alexander D. and Tokunaga, Rumi},
  Journal                  = {Attention, Perception, \& Psychophysics},
  Year                     = {2011},
  Number                   = {6},
  Pages                    = {1886-1902},
  Volume                   = {73},

  Abstract                 = {Contrary to the implication of the term ``lightness constancy'', asymmetric lightness matching has never been found to be perfect unless the scene is highly articulated (i.e., contains a number of different reflectances). Also, lightness constancy has been found to vary for different observers, and an effect of instruction (lightness vs. brightness) has been reported. The elusiveness of lightness constancy presents a great challenge to visual science; we revisit these issues in the following experiment, which involved 44 observers in total. The stimuli consisted of a large sheet of black paper with a rectangular spotlight projected onto the lower half and 40 squares of various shades of grey printed on the upper half. The luminance ratio at the edge of the spotlight was 25, while that of the squares varied from 2 to 16. Three different instructions were given to observers: They were asked to find a square in the upper half that (i) looked as if it was made of the same paper as that on which the spotlight fell (lightness match), (ii) had the same luminance contrast as the spotlight edge (contrast match), or (iii) had the same brightness as the spotlight (brightness match). Observers made 10 matches of each of the three types. Great interindividual variability was found for all three types of matches. In particular, the individual Brunswik ratios were found to vary over a broad range (from .47 to .85). That is, lightness matches were found to be far from veridical. Contrast matches were also found to be inaccurate, being on average, underestimated by a factor of 3.4. Articulation was found to essentially affect not only lightness, but contrast and brightness matches as well. No difference was found between the lightness and luminance contrast matches. While the brightness matches significantly differed from the other matches, the difference was small. Furthermore, the brightness matches were found to be subject to the same interindividual variability and the same effect of articulation. This leads to the conclusion that inexperienced observers are unable to estimate both the brightness and the luminance contrast of the light reflected from real objects lit by real lights. None of our observers perceived illumination edges purely as illumination edges: A partial Gelb effect (``partial illumination discounting'') always took place. The lightness inconstancy in our experiment resulted from this partial illumination discounting. We propose an account of our results based on the two-dimensionality of achromatic colour. We argue that large interindividual variations and the effect of articulation are caused by the large ambiguity of luminance ratios in the stimulus displays used in laboratory conditions.},
  Doi                      = {10.3758/s13414-011-0154-2},
  File                     = {:Papers\\HDRI\\HVS\\Logvinenko2011.pdf:PDF},
  ISSN                     = {1943-393X},
  Url                      = {http://dx.doi.org/10.3758/s13414-011-0154-2}
}

@Article{Maloney1986,
  Title                    = {Color constancy: a method for recovering surface spectral reflectance},
  Author                   = {Laurence T. Maloney and Brian A. Wandell},
  Journal                  = {J. Opt. Soc. Am. A},
  Year                     = {1986},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {29-33},
  Volume                   = {3},

  Abstract                 = {Human and machine visual sensing is enhanced when surface properties of objects in scenes, including color, can be reliably estimated despite changes in the ambient lighting conditions. We describe a computational method for estimating surface spectral reflectance when the spectral power distribution of the ambient light is not known.},
  Doi                      = {10.1364/JOSAA.3.000029},
  File                     = {:Papers\\HDRI\\ColorAppearance\\Maloney1986.pdf:PDF},
  Publisher                = {OSA},
  Url                      = {http://josaa.osa.org/abstract.cfm?URI=josaa-3-1-29}
}

@Article{Mantiuk2008,
  Title                    = {Display Adaptive Tone Mapping},
  Author                   = {Mantiuk, Rafa\l and Daly, Scott and Kerofsky, Louis},
  Journal                  = {ACM Trans. Graph.},
  Year                     = {2008},

  Month                    = aug,
  Number                   = {3},
  Pages                    = {68:1--68:10},
  Volume                   = {27},

  Acmid                    = {1360667},
  Address                  = {New York, NY, USA},
  Articleno                = {68},
  Doi                      = {10.1145/1360612.1360667},
  File                     = {Mantiuk2008.pdf:Papers\\HDRI\\ToneMapping\\Local\\Mantiuk\\Mantiuk2008.pdf:PDF},
  ISSN                     = {0730-0301},
  Issue_date               = {August 2008},
  Keywords                 = {display-adaptive, high dynamic range, image reproduction, optimization, tone mapping, viewing conditions, visual perception},
  Numpages                 = {10},
  Owner                    = {yangfan},
  Publisher                = {ACM},
  Timestamp                = {2016.04.19},
  Url                      = {http://doi.acm.org/10.1145/1360612.1360667}
}

@Unpublished{Mantiuk2008supp,
  Title                    = {Display Adaptive Tone Mapping - Supplementary Materials},
  Author                   = {Mantiuk, Rafa\l and Daly, Scott and Kerofsky, Louis},
  Year                     = {2008},

  File                     = {:Papers\\HDRI\\ToneMapping\\Local\\Mantiuk\\opttmo_supp.pdf:PDF},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.19},
  Url                      = {http://resources.mpi-inf.mpg.de/hdr/datmo/results/opttmo_supp.pdf}
}

@Article{Mantiuk2011,
  Title                    = {{HDR-VDP}-2: A Calibrated Visual Metric for Visibility and Quality Predictions in All Luminance Conditions},
  Author                   = {Mantiuk, Rafat and Kim, Kil Joong and Rempel, Allan G. and Heidrich, Wolfgang},
  Journal                  = {ACM Trans. Graph.},
  Year                     = {2011},

  Month                    = jul,
  Number                   = {4},
  Pages                    = {40:1--40:14},
  Volume                   = {30},

  Acmid                    = {1964935},
  Address                  = {New York, NY, USA},
  Articleno                = {40},
  Doi                      = {10.1145/2010324.1964935},
  File                     = {:Papers\\HDRI\\ToneMapping\\Evaluation\\mantiuk2011.pdf:PDF},
  ISSN                     = {0730-0301},
  Issue_date               = {July 2011},
  Keywords                 = {high dynamic range, image quality, visual metric, visual model, visual perception},
  Numpages                 = {14},
  Publisher                = {ACM},
  Url                      = {http://doi.acm.org/10.1145/2010324.1964935}
}

@Article{Melo2015,
  Title                    = {Screen reflections impact on {HDR} video tone mapping for mobile devices: an evaluation study},
  Author                   = {Miguel Melo and Maximino Bessa and Lu¨ªs Barbosa and Kurt Debattista and Alan Chalmers},
  Journal                  = {EURASIP Journal on Image and Video Processing},
  Year                     = {2015},
  Volume                   = {2015},

  Doi                      = {10.1186/s13640-015-0094-1},
  File                     = {Melo2015.pdf:Papers\\HDRI\\ToneMapping\\Evaluation\\Melo2015.pdf:PDF},
  Owner                    = {FanYang},
  Timestamp                = {2016.01.20},
  Url                      = {www.jivp.eurasipjournals.com/content/pdf/s13640-015-0094-1.pdf}
}

@Article{Melo2015b,
  Title                    = {Evaluation of Tone-Mapping Operators for HDR Video Under Different Ambient Luminance Levels},
  Author                   = {Melo, M. and Bessa, M. and Debattista, K. and Chalmers, A.},
  Journal                  = {Computer Graphics Forum},
  Year                     = {2015},
  Number                   = {8},
  Pages                    = {38--49},
  Volume                   = {34},

  Doi                      = {10.1111/cgf.12606},
  File                     = {Melo2015b.pdf:Papers\\HDRI\\ToneMapping\\Evaluation\\Melo2015b.pdf:PDF},
  ISSN                     = {1467-8659},
  Keywords                 = {image and video processing, high dynamic range/tone mapping, I.3.3 [Computer Graphics]: Picture/Image Generation¡ªDisplay algorithms, I.4.0 [Computer Graphics]: General¡ªImage displays},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.19},
  Url                      = {http://dx.doi.org/10.1111/cgf.12606}
}

@Article{Meylan2007,
  Title                    = {Model of retinal local adaptation for the tone mapping of color filter array images},
  Author                   = {Laurence Meylan and David Alleysson and Sabine S\"{u}sstrunk},
  Journal                  = {J. Opt. Soc. Am. A},
  Year                     = {2007},

  Month                    = {September},
  Number                   = {9},
  Pages                    = {2807--2816},
  Volume                   = {24},

  Abstract                 = {We present a tone mapping algorithm that is derived from a model of retinal processing. Our approach has two major improvements over existing methods. First, tone mapping is applied directly on the mosaic image captured by the sensor, analogous to the human visual system that applies a nonlinearity to the chromatic responses captured by the cone mosaic. This reduces the number of necessary operations by a factor 3. Second, we introduce a variation of the center/surround class of local tone mapping algorithms, which are known to increase the local contrast of images but tend to create artifacts. Our method gives a good improvement in contrast while avoiding halos and maintaining good global appearance. Like traditional center/surround algorithms, our method uses a weighted average of surrounding pixel values. Instead of being used directly, the weighted average serves as a variable in the Naka-Rushton equation, which models the photoreceptors' nonlinearity. Our algorithm provides pleasing results on various images with different scene content and dynamic range.},
  Doi                      = {10.1364/JOSAA.24.002807},
  File                     = {:Papers\\HDRI\\ToneMapping\\Local\\Meylan2007\\Meylan2007.pdf:PDF},
  Keywords                 = {Digital image processing; Image enhancement; Photography; Color; Vision modeling ; Spatial filtering},
  Publisher                = {OSA},
  Review                   = {http://ivrlwww.epfl.ch/supplementary_material/LM_JOSA06/},
  Url                      = {http://josaa.osa.org/abstract.cfm?URI=josaa-24-9-2807}
}

@Article{Meylan2006,
  Title                    = {High dynamic range image rendering with a retinex-based adaptive filter},
  Author                   = {L. Meylan and S. Susstrunk},
  Journal                  = {IEEE Transactions on Image Processing},
  Year                     = {2006},

  Month                    = {Sept},
  Number                   = {9},
  Pages                    = {2820-2830},
  Volume                   = {15},

  Doi                      = {10.1109/TIP.2006.877312},
  File                     = {:Papers\\HDRI\\ToneMapping\\Local\\Meylan2006\\meylan2006.pdf:PDF},
  ISSN                     = {1057-7149},
  Keywords                 = {adaptive filters;image processing;principal component analysis;rendering (computer graphics);Retinex-based adaptive filter;center-surround Retinex model;chromatic changes;halo artifact reduction;high dynamic range image rendering;human visual system;image high-contrast edges;luminance channel;principal component analysis;Adaptive filters;Displays;Dynamic range;Humans;Image coding;Layout;Principal component analysis;Rendering (computer graphics);Shape;Visual system;Color image rendering;high dynamic range;surround-based Retinex;tone mapping},
  Review                   = {http://ivrl.epfl.ch/page-74617-en.html}
}

@Article{Mizokami2014,
  Title                    = {Color constancy influenced by unnatural spatial structure},
  Author                   = {Yoko Mizokami and Hirohisa Yaguchi},
  Journal                  = {J. Opt. Soc. Am. A},
  Year                     = {2014},

  Month                    = {Apr},
  Number                   = {4},
  Pages                    = {A179--A185},
  Volume                   = {31},

  Abstract                 = {The recognition of spatial structures is important for color constancy because we cannot identify an object\&\#x2019;s color under different illuminations without knowing which space it is in and how that space is illuminated. To show the importance of the natural structure of environments on color constancy, we investigated the way in which color appearance was affected by unnatural viewing conditions in which a spatial structure was distorted. Observers judged the color of a test patch placed in the center of a small room illuminated by white or reddish lights, as well as two rooms illuminated by white and reddish light, respectively. In the natural viewing condition, an observer saw the room(s) through a viewing window, whereas in an unnatural viewing condition, the scene structure was scrambled by a kaleidoscope-type viewing box. Results of single room condition with one illuminant color showed little difference in color constancy between the two viewing conditions. However, it decreased in the two-rooms condition with a more complex arrangement of space and illumination. The patch\&\#x2019;s appearance under the unnatural viewing condition was more influenced by simultaneous contrast than its appearance under the natural viewing condition. It also appears that color appearance under white illumination is more stable compared to that under reddish illumination. These findings suggest that natural spatial structure plays an important role for color constancy in a complex environment.},
  Doi                      = {10.1364/JOSAA.31.00A179},
  File                     = {:Papers\\HDRI\\ColorAppearance\\mizokami2014.pdf:PDF},
  Keywords                 = {Vision, color, and visual optics ; Color vision; Psychophysics},
  Publisher                = {OSA},
  Url                      = {http://josaa.osa.org/abstract.cfm?URI=josaa-31-4-A179}
}

@InProceedings{Narasimha2015,
  Title                    = {A real-time high dynamic range HD video camera},
  Author                   = {Narasimha, R. and Batur, U.},
  Booktitle                = {Computer Vision and Pattern Recognition Workshops (CVPRW), 2015 IEEE Conference on},
  Year                     = {2015},
  Month                    = {June},
  Pages                    = {35-41},

  Doi                      = {10.1109/CVPRW.2015.7301364},
  File                     = {Narasimha2015.pdf:Papers\\HDRI\\ToneMapping\\Local\\Narasimha2015.pdf:PDF},
  Keywords                 = {image sensors;intelligent sensors;real-time systems;video cameras;dynamic range enhancement;embedded real-time HDR video camera system;high dynamic range imaging;image content;tone mapping;Cameras;Dynamic range;Floors;Real-time systems;Streaming media;Table lookup},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.19}
}

@InCollection{Narwaria2015,
  Title                    = {High Dynamic Range Visual Quality of Experience Measurement: Challenges and Perspectives},
  Author                   = {Narwaria, Manish and Da Silva, MatthieuPerreira and Le Callet, Patrick},
  Booktitle                = {Visual Signal Quality Assessment},
  Publisher                = {Springer International Publishing},
  Year                     = {2015},
  Editor                   = {Deng, Chenwei and Ma, Lin and Lin, Weisi and Ngan, King Ngi},
  Pages                    = {129-155},

  Doi                      = {10.1007/978-3-319-10368-6_5},
  File                     = {Narwaria2015.pdf:Papers\\HDRI\\ToneMapping\\Evaluation\\Narwaria2015.pdf:PDF},
  ISBN                     = {978-3-319-10367-9},
  Language                 = {English},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.19},
  Url                      = {http://dx.doi.org/10.1007/978-3-319-10368-6_5}
}

@Article{Narwaria2015b,
  Title                    = {{HDR-VDP-2.2}: a calibrated method for objective quality prediction of high-dynamic range and standard images},
  Author                   = {Manish Narwaria and Rafal Mantiuk and Mattheiu P. Da Silva and Patrick Le Callet},
  Journal                  = {Journal of Electronic Imaging},
  Year                     = {2015},

  Month                    = {January},
  Number                   = {1},
  Volume                   = {24},

  Doi                      = {http://dx.doi.org/10.1117/1.JEI.24.1.010501},
  File                     = {:Papers\\HDRI\\ToneMapping\\Evaluation\\Narwaria2015b.pdf:PDF},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.19},
  Url                      = {http://spie.org/Publications/Journal/10.1117/1.JEI.24.1.010501}
}

@InProceedings{Nasiopoulos2014,
  Title                    = {Evaluation of high dynamic range content viewing experience using eye-tracking data},
  Author                   = {Nasiopoulos, E. and Yuanyuan Dong and Kingstone, A.},
  Booktitle                = {Heterogeneous Networking for Quality, Reliability, Security and Robustness (QShine), 2014 10th International Conference on},
  Year                     = {2014},
  Month                    = {Aug},
  Pages                    = {13-17},

  Doi                      = {10.1109/QSHINE.2014.6928653},
  File                     = {Nasiopoulos2014.pdf:Papers\\HDRI\\ToneMapping\\Evaluation\\Nasiopoulos2014.pdf:PDF},
  Keywords                 = {gaze tracking;image processing;HDR technology;LDR technology;camera design;consumer display products;high dynamic range content viewing experience evaluation;human visual experience;low dynamic range technology;objective eye movement measures;objective performance measures;subjective eye movement measures;vis-a-vis eye-tracking data;visual attention models;Dynamic range;Image color analysis;Monitoring;Tracking;Video sequences;Videos;Visualization;Eye-Tracking;HDR;High dynamic range;Visual attention model},
  Owner                    = {yangfan},
  Timestamp                = {2016.04.19}
}

@InBook{Nguyen2014,
  Title                    = {Computer Vision -- ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part VII},
  Author                   = {Nguyen, Rang M. H. and Prasad, Dilip K. and Brown, Michael S.},
  Chapter                  = {Training-Based Spectral Reconstruction from a Single RGB Image},
  Editor                   = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
  Pages                    = {186-201},
  Publisher                = {Springer International Publishing},
  Year                     = {2014},

  Address                  = {Cham},

  Doi                      = {10.1007/978-3-319-10584-0_13},
  File                     = {:Papers\\HDRI\\ColorAppearance\\nguyen2014.pdf:PDF},
  ISBN                     = {978-3-319-10584-0},
  Url                      = {http://dx.doi.org/10.1007/978-3-319-10584-0_13}
}

@Article{Pizlo1994,
  Title                    = {A theory of shape constancy based on perspective invariants },
  Author                   = {Zygmunt Pizlo},
  Journal                  = {Vision Research },
  Year                     = {1994},
  Number                   = {12},
  Pages                    = {1637 - 1658},
  Volume                   = {34},

  Abstract                 = {Shape constancy refers to the phenomenon in which the percept of the shape of a given object remains constant despite changes in the shape of the object's retinal image. The phenomenon of shape constancy is considered from historical, theoretical and empirical perspectives in this paper. First, four prior theories are discussed; specifically, (1) Helmholtzian theory, which assumes that shape constancy is achieved by taking an object's orientation into account, (2) Gestalt theory, which assumes that shape constancy involves a relationship between the perceived shape and perceived orientation of an object, (3) Gibsonian theory, which assumes that shape constancy is based on projective invariants and (4) multiple view theory, which assumes that shape constancy is achieved by memorizing a large set of different views of the object. It is shown, by an analysis of the prior literature, that none of these theories can actually explain the phenomenon of shape constancy. A new theory, which is based on new perspective invariants of a flat shape, is then proposed. The new Perspective Invariants Theory can account for all prior shape constancy experiments. New experiments, testing predictions of the Perspective Invariants Theory are then described. These experiments showed that: (1) a novel shape can be matched with its single perspective image in the absence of depth cues, (2) perceptual processing of shape is impaired when the range of possible values of tilt is wide, (3) perceptual processing of shape is not affected by the width of the range of possible values of slant. These results support predictions of Perspective Invariants Theory. },
  Doi                      = {http://dx.doi.org/10.1016/0042-6989(94)90123-6},
  File                     = {:Papers\\HDRI\\HVS\\pizlo1994.pdf:PDF},
  ISSN                     = {0042-6989},
  Keywords                 = {Shape constancy Shape perceptionPerspective invariants },
  Url                      = {http://www.sciencedirect.com/science/article/pii/0042698994901236}
}

@InProceedings{Robles-Kelly2015,
  Title                    = {Single Image Spectral Reconstruction for Multimedia Applications},
  Author                   = {Robles-Kelly, Antonio},
  Booktitle                = {Proceedings of the 23rd ACM International Conference on Multimedia},
  Year                     = {2015},

  Address                  = {New York, NY, USA},
  Pages                    = {251--260},
  Publisher                = {ACM},
  Series                   = {MM '15},

  Acmid                    = {2806223},
  Doi                      = {10.1145/2733373.2806223},
  File                     = {:Papers\\HDRI\\ColorAppearance\\Robles-Kelly2015.pdf:PDF},
  ISBN                     = {978-1-4503-3459-4},
  Keywords                 = {image reproduction and enhacement, sparse coding, spectral reconstruction},
  Location                 = {Brisbane, Australia},
  Numpages                 = {10},
  Url                      = {http://doi.acm.org/10.1145/2733373.2806223}
}

@Article{Todorovic2006,
  Title                    = {Lightness, illumination, and gradients},
  Author                   = {Todorovi\'{c}, Dejan},
  Journal                  = {Spatial Vision},
  Year                     = {2006},
  Number                   = {2},
  Pages                    = {219-261},
  Volume                   = {19},

  Doi                      = {http://dx.doi.org/10.1163/156856806776923407},
  File                     = {:Papers\\HDRI\\HVS\\todorovic2006.pdf:PDF},
  Url                      = {http://booksandjournals.brillonline.com/content/journals/10.1163/156856806776923407}
}

@Article{Vangorp2015,
  Title                    = {A Model of Local Adaptation},
  Author                   = {Vangorp, Peter and Myszkowski, Karol and Graf, Erich W. and Mantiuk, Rafa\l K.},
  Journal                  = {ACM Trans. Graph.},
  Year                     = {2015},

  Month                    = {October},
  Number                   = {6},
  Pages                    = {166:1--166:13},
  Volume                   = {34},

  Acmid                    = {2818086},
  Address                  = {New York, NY, USA},
  Articleno                = {166},
  Doi                      = {10.1145/2816795.2818086},
  File                     = {:Papers\\HDRI\\ToneMapping\\Local\\Mantiuk\\vangorp2015.pdf:PDF},
  ISSN                     = {0730-0301},
  Issue_date               = {November 2015},
  Keywords                 = {glare, high dynamic range, local adaptation, perception, tone mapping, visual metric},
  Numpages                 = {13},
  Publisher                = {ACM},
  Url                      = {http://doi.acm.org/10.1145/2816795.2818086}
}

@Article{Yuan2015,
  Title                    = {Single-image shadow detection and removal using local colour constancy computation},
  Author                   = {X. Yuan and M. Ebner and Z. Wang},
  Journal                  = {IET Image Processing},
  Year                     = {2015},
  Number                   = {2},
  Pages                    = {118-126},
  Volume                   = {9},

  Abstract                 = {This study is concerned with the problem of shadow detection and removal from single images of natural scenes. In this work, the authors propose a shadow detection method with a surface descriptor, termed colour-shade, which allows them to include the physical considerations derived from the image formation model capturing gradual colour surface variations. The authors incorporate a colour-shade descriptor into the condition random field model to find same illumination pairs and to obtain coherent shadow regions. The authors propose a shadow removal method using an improved local colour constancy computation, which uses anisotropic diffusion to estimate the illuminant locally for each image pixel in shadow. The authors evaluate their method on two shadow detection databases. The experimental results demonstrate that their shadow detection and removal method is state of the art.},
  Doi                      = {10.1049/iet-ipr.2014.0242},
  File                     = {:Papers\\HDRI\\ColorAppearance\\Yuan2015.pdf:PDF},
  ISSN                     = {1751-9659},
  Keywords                 = {image colour analysis;visual databases;colour shade descriptor;condition random field model;gradual colour surface variations;image formation model;image pixel;local colour constancy computation;natural scenes;physical considerations;shadow detection databases;shadow regions;single image shadow detection;single image shadow removal;surface descriptor;termed colour-shade}
}

@TechReport{SMPTE2015,
  Title                    = {Study Group Report {High-Dynamic-Range (HDR)} Imaging Ecosystem},
  Institution              = {SMPTE},
  Year                     = {2015},

  File                     = {SMPTE2015.pdf:Papers\\HDRI\\Overview\\SMPTE2015.pdf:PDF},
  Owner                    = {FanYang},
  Timestamp                = {2016.01.20},
  Url                      = {https://www.smpte.org/sites/default/files/Study%20Group%20On%20High-Dynamic-Range-HDR-Ecosystem.pdf}
}

